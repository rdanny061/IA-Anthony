{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC2kuHslYZJ2"
   },
   "source": [
    "# Live demo - Anthony"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ihj-qsLAYnSZ"
   },
   "source": [
    "## Importaciones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Wi4zDNpjSKyg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEulVqc5YwEd"
   },
   "source": [
    "## Se prepara el modelo (esta vez no pre-entrenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qfvqFq8UYses"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.cuda().eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pygd1wpKY_go"
   },
   "source": [
    "## Se carga el modelo que se entrenó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "az6E_O1wZCVD"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_resnet18.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yXjiFrLZI27"
   },
   "source": [
    "## Se define 'cuda' para que no se quede sin ejecutar en la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oDx4k2MEZE4l"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGe5-wKnZT4I"
   },
   "source": [
    "## Se optienen las librerías de TensorRT para optimizar el modelo, con esto se crea un modelo nuevo que será utilizado en el live demo (puede demorar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zXC7pLw_Zhis"
   },
   "outputs": [],
   "source": [
    "from torch2trt import torch2trt\n",
    "\n",
    "data = torch.zeros((1, 3, 224, 224)).cuda().half()\n",
    "\n",
    "model_trt = torch2trt(model, [data], fp16_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YC1fE-eTZmWi"
   },
   "outputs": [],
   "source": [
    "torch.save(model_trt.state_dict(), 'best_model_trt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSHitvyMZq9u"
   },
   "source": [
    "## Se carga el modelo optimizado\n",
    "\n",
    "---\n",
    "\n",
    "Se convierten las imágenes de la cámara al mismo formato que las necesita el modelo. Para esto, convertimos de diseño HWC a diseño CHW.\n",
    "\n",
    "Transferimos los datos del CPU al GPU y añadimos la dimensión del batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CGXCR4_faDXF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('best_model_trt.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AeTKvN8HaGbV"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, std)\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSWI8NtUaKgo"
   },
   "source": [
    "## Mostramos la cámara\n",
    "\n",
    "---\n",
    "\n",
    "Se muestra la cámara para ver lo que el robot está viendo. Se instancia el robot para controlar sus motores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nvojq8UZlGxe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f661be4a7f6f44cc91056ea47545cbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.HBox([image, blocked_slider]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "y4Gn4lEWlJza"
   },
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFXeDo41lU8u"
   },
   "source": [
    "## Configurar la fuerza de los motores\n",
    "\n",
    "---\n",
    "\n",
    "Esto resulta necesario por la desventaja que tiene uno de los motores de Anthony, por lo que se requiere configurar de diferente manera la fuerza de los motores. \n",
    "\n",
    "La configuración fue:\n",
    "> motor izquierdo : 2.5\n",
    "\n",
    "> motor derecho : 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9gxtAP6Glr3D"
   },
   "outputs": [],
   "source": [
    "robot.left_motor.alpha =2.5\n",
    "robot.right_motor.alpha = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDsiYbJPs3YI"
   },
   "source": [
    "## Función que le permitirá al robot observar cada cambio en la cámara\n",
    "\n",
    "---\n",
    "\n",
    "Esta función realiza los siguientes pasos:\n",
    "\n",
    "\n",
    "1.   Pre procesa la imagen recibida\n",
    "2.   Ejecuta la red neuronal\n",
    "3.   Calcula el valor de la dirección\n",
    "4.   Controla los motores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RawJoXUGtFx-"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "def update(change):\n",
    "    global blocked_slider, robot\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model_trt(x)\n",
    "    #print(y)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    #print(y)\n",
    "    \n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    #print(prob_blocked)\n",
    "    \n",
    "    blocked_slider.value = prob_blocked\n",
    "    \n",
    "    if prob_blocked < 0.5:\n",
    "        robot.forward(0.20)\n",
    "    else:\n",
    "        robot.left(0.19)\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value})  # we call the function once to intialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKdveuZ721G3"
   },
   "source": [
    "## Se agrega el observador a la cámara para que esta llame la función con vada cambio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Z8PhY5e927Lk"
   },
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MsMJOHkq29Sh"
   },
   "outputs": [],
   "source": [
    "camera.stop() # se detiene la cámara "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyOWKAco3A6R"
   },
   "source": [
    "## Se detiene el observador y el robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ja-4yc1c3FIk"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(update, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM93PoaOAxSGa2kodfZbZK+",
   "name": "live_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
