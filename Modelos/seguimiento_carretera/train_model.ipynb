{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_model.ipynb","provenance":[],"authorship_tag":"ABX9TyOo61Y9seskLu4Nz/CchRmD"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CjSpF6NXTw5W"},"source":["# Entrenamiento de los datos para seguimiento de carretera - **Anthony**\n","---\n","Para realizar el entrenamiento de la red neuronal para el seguimiento, se tomará el set de datos precapturado en el notebook data_collection. Para esto se utilizará pythorch y una red ya pre entrenada de resnet-18."]},{"cell_type":"markdown","metadata":{"id":"_hYBcWlaUK-6"},"source":["# Importaciones necesarias"]},{"cell_type":"code","metadata":{"id":"IzqxDDwESmxu"},"source":["import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import glob\n","import PIL.Image\n","import os\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTHLpDsrUmxH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"azhQvE20UVXl"},"source":["# Instancias del dataset\n","\n","---\n","\n","En esta parte del código conseguimos los valores de \"x\" y \"y\" del label del nombre de la imagen. Además aplicamos algunas transformaciones de las imágenes como color jitter, hacemos horizontal flips en caso de querer seguir un camino que no sea recto, entonces toma algunas imágenes un poco torcidas."]},{"cell_type":"code","metadata":{"id":"jZHrgoGKUvTW"},"source":["def get_x(path):\n","    \"\"\"Gets the x value from the image filename\"\"\"\n","    return (float(int(path[3:6])) - 50.0) / 50.0\n","\n","\n","def get_y(path):\n","    \"\"\"Gets the y value from the image filename\"\"\"\n","    return (float(int(path[7:10])) - 50.0) / 50.0\n","\n","class XYDataset(torch.utils.data.Dataset):\n","    \n","    def __init__(self, directory, random_hflips=False):\n","        self.directory = directory\n","        self.random_hflips = random_hflips\n","        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))\n","        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n","    \n","    def __len__(self):\n","        return len(self.image_paths)\n","    \n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        \n","        image = PIL.Image.open(image_path)\n","        x = float(get_x(os.path.basename(image_path)))\n","        y = float(get_y(os.path.basename(image_path)))\n","        \n","        if float(np.random.rand(1)) > 0.5:\n","            image = transforms.functional.hflip(image)\n","            x = -x\n","        \n","        image = self.color_jitter(image)\n","        image = transforms.functional.resize(image, (224, 224))\n","        image = transforms.functional.to_tensor(image)\n","        image = image.numpy()[::-1].copy()\n","        image = torch.from_numpy(image)\n","        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        \n","        return image, torch.tensor([x, y]).float()\n","    \n","dataset = XYDataset('dataset', random_hflips=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eODrzcQ1U3eb"},"source":["# Dividir el dataset\n","\n","---\n","\n","Se divide el dataset en train y test. En este caso 90% destinado para entrenamiento y 10% para prueba."]},{"cell_type":"code","metadata":{"id":"Tdb1hRSGVGND"},"source":["test_percent = 0.1\n","num_test = int(test_percent * len(dataset))\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aVR9WVgrVLla"},"source":["# Creación de los data loaders y batch size\n","\n","---\n","\n","Usamos la clase ``DataLoader`` para cargar los datos en los batches, además de que permitimos hacer shuffle para que las imágenes se tomen aleatoriamente."]},{"cell_type":"code","metadata":{"id":"wZIz8yKVVhOW"},"source":["train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=16,\n","    shuffle=True,\n","    num_workers=4\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    batch_size=16,\n","    shuffle=True,\n","    num_workers=4\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RPOXiBC3VnSf"},"source":["# Definir la red neuronal\n","\n","---\n","\n","Utilizando ResNet-18, se crea el modelo ya pre-entrado."]},{"cell_type":"code","metadata":{"id":"0cQHkXNQY_g9"},"source":["model = models.resnet18(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uoZt-V7aZBOA"},"source":["model.fc = torch.nn.Linear(512, 2)\n","device = torch.device('cuda')\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-QRgPcDVZ_tC"},"source":["# Entrenamiento\n","\n","---\n","\n","Se entrena por 150 épocas, que fue el número de épocas que mostró mejor resultado."]},{"cell_type":"code","metadata":{"id":"6Z71IxgoZNvZ"},"source":["NUM_EPOCHS = 150\n","BEST_MODEL_PATH = 'best_steering_model_xy.pth'\n","best_loss = 1e9\n","\n","optimizer = optim.Adam(model.parameters())\n","\n","for epoch in range(NUM_EPOCHS):\n","    \n","    model.train()\n","    train_loss = 0.0\n","    for images, labels in iter(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = F.mse_loss(outputs, labels)\n","        train_loss += float(loss)\n","        loss.backward()\n","        optimizer.step()\n","    train_loss /= len(train_loader)\n","    \n","    model.eval()\n","    test_loss = 0.0\n","    for images, labels in iter(test_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        loss = F.mse_loss(outputs, labels)\n","        test_loss += float(loss)\n","    test_loss /= len(test_loader)\n","    \n","    print('Época: %f - ( TrainAccuracy: %f, TrainLoss: %f ) - ( TestAccuracy: %f, TestLoss: %f )' % (epoch, 1.0-train_loss, train_loss, 1.0-test_loss,test_loss))\n","    if test_loss < best_loss:\n","        torch.save(model.state_dict(), BEST_MODEL_PATH)\n","        best_loss = test_loss"],"execution_count":null,"outputs":[]}]}